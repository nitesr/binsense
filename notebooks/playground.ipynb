{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Obtaining file:///Users/n0c09jf/code/github/binsense/libs\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: binsense-libs\n",
      "  Building editable for binsense-libs (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for binsense-libs: filename=binsense_libs-0.0.1-py2.py3-none-any.whl size=1137 sha256=8524b93cea3793ac8f93136a46b3b775f211868867a04c7e319690205c497b92\n",
      "  Stored in directory: /private/var/folders/vm/2g2pvy116zzglvllmm0n_f100000gx/T/pip-ephem-wheel-cache-ibxzsdqi/wheels/77/72/16/1e76e1dcd0e567ae2a1096c6d731674e5dee84ed8ab15b770d\n",
      "Successfully built binsense-libs\n",
      "Installing collected packages: binsense-libs\n",
      "  Attempting uninstall: binsense-libs\n",
      "    Found existing installation: binsense-libs 0.0.1\n",
      "    Uninstalling binsense-libs-0.0.1:\n",
      "      Successfully uninstalled binsense-libs-0.0.1\n",
      "Successfully installed binsense-libs-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# install packages in libs (as editable)\n",
    "!python -m pip install -e ../libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/n0c09jf/code/github/binsense/_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading bin-metadata: 100%|██████████| 3875/3875 [00:43<00:00, 90.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3875, 6) (10144, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from binsense.config import DATA_DIR\n",
    "print(DATA_DIR)\n",
    "\n",
    "import binsense.downloader as d\n",
    "d.download()\n",
    "\n",
    "import binsense.metadata as m\n",
    "bin_df, item_df = m.load()\n",
    "print(bin_df.shape, item_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json /Users/n0c09jf/.cache/huggingface/hub/models--google--owlv2-base-patch16-ensemble/snapshots/7c77fc1316a353da3109f81d80ae118dd58fd55b/config.json\n",
      "model.safetensors /Users/n0c09jf/.cache/huggingface/hub/models--google--owlv2-base-patch16-ensemble/snapshots/7c77fc1316a353da3109f81d80ae118dd58fd55b/model.safetensors\n",
      "dict_keys(['box_head.dense0.bias', 'box_head.dense0.weight', 'box_head.dense1.bias', 'box_head.dense1.weight', 'box_head.dense2.bias', 'box_head.dense2.weight', 'class_head.dense0.bias', 'class_head.dense0.weight', 'class_head.logit_scale.bias', 'class_head.logit_scale.weight', 'class_head.logit_shift.bias', 'class_head.logit_shift.weight', 'layer_norm.bias', 'layer_norm.weight', 'objectness_head.dense0.bias', 'objectness_head.dense0.weight', 'objectness_head.dense1.bias', 'objectness_head.dense1.weight', 'objectness_head.dense2.bias', 'objectness_head.dense2.weight', 'owlv2.logit_scale', 'owlv2.text_model.embeddings.position_embedding.weight', 'owlv2.text_model.embeddings.token_embedding.weight', 'owlv2.text_model.encoder.layers.0.layer_norm1.bias', 'owlv2.text_model.encoder.layers.0.layer_norm1.weight', 'owlv2.text_model.encoder.layers.0.layer_norm2.bias', 'owlv2.text_model.encoder.layers.0.layer_norm2.weight', 'owlv2.text_model.encoder.layers.0.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.0.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.0.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.0.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.0.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.0.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.0.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.0.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.0.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.0.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.0.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.0.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.1.layer_norm1.bias', 'owlv2.text_model.encoder.layers.1.layer_norm1.weight', 'owlv2.text_model.encoder.layers.1.layer_norm2.bias', 'owlv2.text_model.encoder.layers.1.layer_norm2.weight', 'owlv2.text_model.encoder.layers.1.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.1.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.1.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.1.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.1.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.1.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.1.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.1.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.1.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.1.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.1.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.1.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.10.layer_norm1.bias', 'owlv2.text_model.encoder.layers.10.layer_norm1.weight', 'owlv2.text_model.encoder.layers.10.layer_norm2.bias', 'owlv2.text_model.encoder.layers.10.layer_norm2.weight', 'owlv2.text_model.encoder.layers.10.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.10.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.10.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.10.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.10.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.10.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.10.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.10.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.10.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.10.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.10.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.10.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.11.layer_norm1.bias', 'owlv2.text_model.encoder.layers.11.layer_norm1.weight', 'owlv2.text_model.encoder.layers.11.layer_norm2.bias', 'owlv2.text_model.encoder.layers.11.layer_norm2.weight', 'owlv2.text_model.encoder.layers.11.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.11.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.11.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.11.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.11.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.11.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.11.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.11.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.11.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.11.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.11.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.11.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.2.layer_norm1.bias', 'owlv2.text_model.encoder.layers.2.layer_norm1.weight', 'owlv2.text_model.encoder.layers.2.layer_norm2.bias', 'owlv2.text_model.encoder.layers.2.layer_norm2.weight', 'owlv2.text_model.encoder.layers.2.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.2.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.2.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.2.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.2.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.2.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.2.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.2.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.2.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.2.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.2.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.2.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.3.layer_norm1.bias', 'owlv2.text_model.encoder.layers.3.layer_norm1.weight', 'owlv2.text_model.encoder.layers.3.layer_norm2.bias', 'owlv2.text_model.encoder.layers.3.layer_norm2.weight', 'owlv2.text_model.encoder.layers.3.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.3.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.3.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.3.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.3.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.3.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.3.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.3.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.3.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.3.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.3.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.3.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.4.layer_norm1.bias', 'owlv2.text_model.encoder.layers.4.layer_norm1.weight', 'owlv2.text_model.encoder.layers.4.layer_norm2.bias', 'owlv2.text_model.encoder.layers.4.layer_norm2.weight', 'owlv2.text_model.encoder.layers.4.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.4.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.4.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.4.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.4.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.4.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.4.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.4.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.4.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.4.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.4.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.4.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.5.layer_norm1.bias', 'owlv2.text_model.encoder.layers.5.layer_norm1.weight', 'owlv2.text_model.encoder.layers.5.layer_norm2.bias', 'owlv2.text_model.encoder.layers.5.layer_norm2.weight', 'owlv2.text_model.encoder.layers.5.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.5.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.5.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.5.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.5.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.5.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.5.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.5.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.5.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.5.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.5.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.5.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.6.layer_norm1.bias', 'owlv2.text_model.encoder.layers.6.layer_norm1.weight', 'owlv2.text_model.encoder.layers.6.layer_norm2.bias', 'owlv2.text_model.encoder.layers.6.layer_norm2.weight', 'owlv2.text_model.encoder.layers.6.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.6.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.6.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.6.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.6.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.6.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.6.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.6.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.6.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.6.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.6.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.6.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.7.layer_norm1.bias', 'owlv2.text_model.encoder.layers.7.layer_norm1.weight', 'owlv2.text_model.encoder.layers.7.layer_norm2.bias', 'owlv2.text_model.encoder.layers.7.layer_norm2.weight', 'owlv2.text_model.encoder.layers.7.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.7.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.7.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.7.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.7.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.7.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.7.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.7.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.7.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.7.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.7.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.7.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.8.layer_norm1.bias', 'owlv2.text_model.encoder.layers.8.layer_norm1.weight', 'owlv2.text_model.encoder.layers.8.layer_norm2.bias', 'owlv2.text_model.encoder.layers.8.layer_norm2.weight', 'owlv2.text_model.encoder.layers.8.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.8.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.8.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.8.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.8.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.8.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.8.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.8.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.8.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.8.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.8.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.8.self_attn.v_proj.weight', 'owlv2.text_model.encoder.layers.9.layer_norm1.bias', 'owlv2.text_model.encoder.layers.9.layer_norm1.weight', 'owlv2.text_model.encoder.layers.9.layer_norm2.bias', 'owlv2.text_model.encoder.layers.9.layer_norm2.weight', 'owlv2.text_model.encoder.layers.9.mlp.fc1.bias', 'owlv2.text_model.encoder.layers.9.mlp.fc1.weight', 'owlv2.text_model.encoder.layers.9.mlp.fc2.bias', 'owlv2.text_model.encoder.layers.9.mlp.fc2.weight', 'owlv2.text_model.encoder.layers.9.self_attn.k_proj.bias', 'owlv2.text_model.encoder.layers.9.self_attn.k_proj.weight', 'owlv2.text_model.encoder.layers.9.self_attn.out_proj.bias', 'owlv2.text_model.encoder.layers.9.self_attn.out_proj.weight', 'owlv2.text_model.encoder.layers.9.self_attn.q_proj.bias', 'owlv2.text_model.encoder.layers.9.self_attn.q_proj.weight', 'owlv2.text_model.encoder.layers.9.self_attn.v_proj.bias', 'owlv2.text_model.encoder.layers.9.self_attn.v_proj.weight', 'owlv2.text_model.final_layer_norm.bias', 'owlv2.text_model.final_layer_norm.weight', 'owlv2.text_projection.weight', 'owlv2.vision_model.embeddings.class_embedding', 'owlv2.vision_model.embeddings.patch_embedding.weight', 'owlv2.vision_model.embeddings.position_embedding.weight', 'owlv2.vision_model.encoder.layers.0.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.0.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.0.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.0.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.0.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.0.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.0.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.0.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.1.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.1.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.1.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.1.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.1.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.1.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.1.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.1.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.10.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.10.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.10.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.10.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.10.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.10.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.10.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.10.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.11.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.11.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.11.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.11.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.11.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.11.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.11.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.11.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.2.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.2.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.2.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.2.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.2.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.2.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.2.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.2.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.3.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.3.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.3.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.3.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.3.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.3.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.3.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.3.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.4.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.4.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.4.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.4.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.4.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.4.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.4.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.4.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.5.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.5.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.5.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.5.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.5.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.5.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.5.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.5.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.6.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.6.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.6.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.6.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.6.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.6.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.6.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.6.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.7.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.7.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.7.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.7.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.7.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.7.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.7.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.7.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.8.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.8.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.8.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.8.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.8.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.8.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.8.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.8.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'owlv2.vision_model.encoder.layers.9.layer_norm1.bias', 'owlv2.vision_model.encoder.layers.9.layer_norm1.weight', 'owlv2.vision_model.encoder.layers.9.layer_norm2.bias', 'owlv2.vision_model.encoder.layers.9.layer_norm2.weight', 'owlv2.vision_model.encoder.layers.9.mlp.fc1.bias', 'owlv2.vision_model.encoder.layers.9.mlp.fc1.weight', 'owlv2.vision_model.encoder.layers.9.mlp.fc2.bias', 'owlv2.vision_model.encoder.layers.9.mlp.fc2.weight', 'owlv2.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'owlv2.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'owlv2.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'owlv2.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'owlv2.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'owlv2.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'owlv2.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'owlv2.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'owlv2.vision_model.post_layernorm.bias', 'owlv2.vision_model.post_layernorm.weight', 'owlv2.vision_model.pre_layernorm.bias', 'owlv2.vision_model.pre_layernorm.weight', 'owlv2.visual_projection.weight'])\n",
      "{\n",
      "  \"architectures\": [\n",
      "    \"Owlv2ForObjectDetection\"\n",
      "  ],\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"logit_scale_init_value\": 2.6592,\n",
      "  \"model_type\": \"owlv2\",\n",
      "  \"projection_dim\": 512,\n",
      "  \"text_config\": {\n",
      "    \"model_type\": \"owlv2_text_model\"\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.0.dev0\",\n",
      "  \"vision_config\": {\n",
      "    \"image_size\": 960,\n",
      "    \"model_type\": \"owlv2_vision_model\",\n",
      "    \"patch_size\": 16\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors import safe_open\n",
    "\n",
    "import json, torch\n",
    "\n",
    "cfg_file_path = hf_hub_download(repo_id=\"google/owlv2-base-patch16-ensemble\", filename=\"config.json\")\n",
    "print('config.json', cfg_file_path)\n",
    "\n",
    "model_file_path = hf_hub_download(repo_id=\"google/owlv2-base-patch16-ensemble\", filename=\"model.safetensors\")\n",
    "print('model.safetensors', model_file_path)\n",
    "\n",
    "preproc_file_path = hf_hub_download(repo_id=\"google/owlv2-base-patch16-ensemble\", filename=\"preprocessor_config.json\")\n",
    "print('preprocessor_config.json', preproc_file_path)\n",
    "\n",
    "state_dict = {}\n",
    "with safe_open(model_file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "   for key in f.keys():\n",
    "       state_dict[key] = f.get_tensor(key)\n",
    "print(state_dict.keys())\n",
    "\n",
    "with open(cfg_file_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "print(json.dumps(config, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binsense1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
